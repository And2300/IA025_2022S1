{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula1_Exercícios_20210718.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e9S5acRbm1Zr",
        "udS0Ns4etoJs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/And2300/IA025_2022S1/blob/main/Aula1_Exerc%C3%ADcios_20210718.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34eb9a1-bff5-48d0-e7b6-a8374816564a"
      },
      "source": [
        "print('Meu nome é: Andersson')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Andersson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}\n",
        "\n",
        "HINT: https://rico-schmidt.name/pymotw-3/collections/counter.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "import collections \n",
        "def top_k(L, k):\n",
        "    # Escreva aqui o código\n",
        "    c=collections.Counter(L).most_common(k)\n",
        "    return dict(c)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b5bb41-d5cd-408d-fd0d-8ecc3dc89693"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b19869-a325-4197-9c50-77f13075c83c"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 516 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras.\n",
        "\n",
        "HINT: \n",
        "* https://www.w3schools.com/python/python_regex.asp\n",
        "* https://www.programiz.com/python-programming/regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "import re\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "    # escreva o código aqui.\n",
        "    tokens = re.findall(r\"[\\w']+|[.,!?;]\", text.lower()) #[\\w']: Matches any alphanumeric character, [.,!?;] : Matches any non-alphanumeric character and space\n",
        "    ids = []\n",
        "    for token in tokens:\n",
        "      ids.append(vocabulary.get(token, vocabulary['unknown']))\n",
        "    return ids"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc2eb99-62ec-49ba-be5a-7a878ca0b268"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7410e4bf-83d2-4a27-e154-5333a35856ba"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.85 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python.\n",
        "\n",
        "HINT: https://www.geeksforgeeks.org/python-random-sample-function/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample(path: str, k: int):\n",
        "    # Escreva o seu código aqui.\n",
        "    archivo = open(path,'r') #open file\n",
        "    return random.sample(archivo.read().split('\\n'),k) #read and split by \\n, them take a sample"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d961d6a9-d2b4-4751-9cf4-c191f0709a82"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 93', 'line 35', 'line 14', 'line 58', 'line 4', 'line 89', 'line 69', 'line 49', 'line 71', 'line 51']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a36cf7d-4de6-4ddd-9234-221b339696fb"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 66.7 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?\n",
        "\n",
        "HINT: \n",
        "* https://mediatum.ub.tum.de/doc/625604/625604\n",
        "* https://www.stat.cmu.edu/~ryantibs/convexopt-F18/scribes/Lecture_19.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: $$m \\cdot (n-1) \\cdot p$$\n",
        "- número de multiplicações: $$m \\cdot n \\cdot p$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6d9687-dc64-4023-c442-136cb6c474cf"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4046c4a-d802-4b0d-ae4d-e8ed7c393cb1"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "%%time\n",
        "print(A.mean(axis=1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.5  8.5 14.5 20.5]\n",
            "CPU times: user 415 µs, sys: 0 ns, total: 415 µs\n",
            "Wall time: 388 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreva sua solução aqui.\n",
        "%%time\n",
        "print(np.mean(A, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRvHL4BoapDJ",
        "outputId": "48650b3f-04e1-4ade-ea44-f7784a1b97a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.5  8.5 14.5 20.5]\n",
            "CPU times: user 1.02 ms, sys: 0 ns, total: 1.02 ms\n",
            "Wall time: 1.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbe1781-df3a-4980-cd61-6a9c06fb6ba5"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "max, min = A.max(), A.min()\n",
        "C=(A-min)/(max - min)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d325f45-ad5e-4149-f843-8b5b8c169494"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "B=A.T\n",
        "maxc, minc = B.max(axis=1), B.min(axis=1)\n",
        "D=(B.T-minc)/(maxc - minc)\n",
        "\n",
        "print(D)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c229288f-d906-4de4-9717-5932f8a88eb5"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "E=A.T\n",
        "maxf, minf = E.max(axis=0), B.min(axis=0)\n",
        "F=(E-minf)/(maxf - minf)\n",
        "\n",
        "print(F.T)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto.\n",
        "\n",
        "$$\\sigma(z)_i=\\frac{e^{z_i}}{\\Sigma_{j=1}^{K}e^{z_j}}$$\n",
        "$$i=1,...,K \\ and \\ z=(z_1,...,z_K) \\ \\epsilon \\ \\mathbb{R}^K$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    # np.exp(x) / np.sum(np.exp(x))\n",
        "    # Escreva sua solução aqui. A.shape: (2,3)\n",
        "    max = np.max(A, axis=1) #shape: (2,)\n",
        "    max_aumentate = max[:, np.newaxis] #shape: (2,1)\n",
        "    exp = np.exp(A-max_aumentate) # shape: (2,3)\n",
        "    \n",
        "    den = np.sum(exp,axis=1)#shape: (2,)\n",
        "    den_aumentate = den[:, np.newaxis]#shape: (2,1)\n",
        "    return exp/den_aumentate# shape: (2,3)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65aca686-0fd5-4cec-a77a-155a7c2e09fd"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45c4cc2-bd93-409d-92a1-0d01617094ae"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842a76f2-54dc-4753-960b-7af188ad83e6"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 228 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727e2112-3875-4666-fe9c-6baf88f894ff"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1\n",
        "\n",
        "HINT: https://www.delftstack.com/es/howto/numpy/one-hot-encoding-numpy/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "    # Escreva seu código aqui.\n",
        "    b = np.zeros((y.size, n_classes)).astype(int)\n",
        "    b[np.arange(y.size),y.ravel()] = 1\n",
        "    return b"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c450f97-ed63-4a52-dca5-e4bf568d8ead"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))\n",
        "print(one_hot(y, N_CLASSES).shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8 6 8 2 6 6 1 4 3 4]\n",
            "[[0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]]\n",
            "(10, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7b4879-1511-4d68-c88e-3a029ecf51c8"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 179 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```\n",
        "\n",
        "HINT: https://www.geeksforgeeks.org/__call__-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "import numpy as np\n",
        "# Escreva seu código aqui.\n",
        "class Normalizer:\n",
        "    def __init__(self,arr):\n",
        "        self.normarr=arr\n",
        "        self.media=np.mean(self.normarr)\n",
        "        self.desv=np.std(self.normarr)\n",
        "    def __call__(self,arr2):\n",
        "        self.normarr2=arr2\n",
        "        zscore = (self.normarr2-np.mean(self.normarr2))/np.std(self.normarr2)\n",
        "        return (zscore*self.desv)+self.media"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8e3c31-0c04-4c1e-e52b-9a40040a25fe"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29b3c3c1-f349-4440-be6a-ea8cf02c03bf"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d49ae49-acc3-4c7c-c17f-942f4345ba16"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5202179-cd49-42bd-9bbb-b406029d92ad"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9fcbf4-8b61-4038-f97b-f6258e5e8d1f"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9888c486-04d5-4a41-bc8e-64fe0454b47d"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cb7008-d90e-4d28-ec72-8a3e0abf2f08"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5e1347-a9d3-4d95-d4c9-852ec8088b22"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b1f9e8-2470-4f1d-d51f-d586552ae0b0"
      },
      "source": [
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "    return J\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "dw = 0.0001\n",
        "print('J(w,x,y): ',J_func(w,x,y))\n",
        "grad = (J_func(w+dw,x,y) - J_func(w-dw,x,y))/(2*dw)\n",
        "print('grad=', grad)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J(w,x,y):  tensor(14.)\n",
            "grad= tensor(-27.9999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfa2fb75-08db-4ba8-abb5-249ae47d6550"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "lossj=[]\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    grad = (J_func(w+dw,x,y) - J_func(w-dw,x,y))/(2*dw)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate*grad\n",
        "    print('w =', w)\n",
        "    lossj.append(J)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(range(iteracoes),lossj)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('J Loss')\n",
        "plt.show()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-27.9999)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1607)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5137)\n",
            "w = tensor([1.6267])\n",
            "i = 3\n",
            "J= tensor(1.9505)\n",
            "grad = tensor(-10.4505)\n",
            "w = tensor([1.7312])\n",
            "i = 4\n",
            "J= tensor(1.0112)\n",
            "grad = tensor(-7.5281)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor(-5.4196)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor(-3.9014)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1407)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0729)\n",
            "grad = tensor(-2.0218)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor(-1.4555)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0472)\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7540)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5432)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3910)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2814)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2027)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1458)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1051)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0756)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2911e-05)\n",
            "grad = tensor(-0.0544)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b44bd0c1-8635-4946-dfaf-58e070fe7185"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "lossj=[]\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    lossj.append(J.detach().numpy()) #tensor to numpy\n",
        "    print('J=', J)\n",
        "    w.retain_grad() # retain_grad\n",
        "    J.backward() #backward\n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate*grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(range(iteracoes),lossj)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('J Loss')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "ddw = [0.0001,0.001,0.01,0.1,1] #0.00001,\n",
        "val = []\n",
        "for dw in ddw:\n",
        "  grad = (J_func(w+dw,x,y) - J_func(w-dw,x,y))/(2*dw)\n",
        "  print(grad)\n",
        "  val.append(grad)\n",
        "\n",
        "plt.plot(ddw,val)\n",
        "plt.xlabel('dw')\n",
        "plt.ylabel('J')\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "vwuVhUkpJXHq",
        "outputId": "298659d3-5408-4c90-b2a0-04501e7677c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-27.9999)\n",
            "tensor(-28.0008)\n",
            "tensor(-28.0000)\n",
            "tensor(-28.0000)\n",
            "tensor(-28.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: O valor de $\\Delta w$ deve ser próximo de zero, mas diferente dele. Esse valor aumenta a precisão no cálculo, mas se tivermos um grande volume de dados, o tempo de processamento aumenta. A otimização do gradiente depende diretamente de $\\Delta w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) De acordo com a forma $\\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w}$, para atualizar w pela aproximação de diferenças finitas e seja w um vetor com N parâmetros, devemos executar N operações. Isso nos dá um custo computacional de $O(N^2)$.\n",
        "\n",
        "b) Por outro lado, para atualizar via retropropagação, calcula suas derivadas parciais apenas uma vez. Para trás e para frente têm o mesmo custo computacional $O(N)$. Então o custo para backpropagation é $O(2N)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$y_j$ é definido como:\n",
        "$$y_i=[0,0,1,0,0,...,0,0]$$\n",
        "\n",
        "consideramos K classes com igual probabilidade, $p_j=\\frac{1}{K}$\n",
        "\n",
        "Operando na função:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log (p_j) $$\n",
        "$$L = - \\log \\left( \\frac{1}{K} \\right) $$\n",
        "$$L = \\log(K)$$\n",
        "\n",
        "o custo computacional será ~ $O(K)$"
      ],
      "metadata": {
        "id": "u4eUjopNc6Zb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}